---
title: "scATACseq - Complete Seurat procedure"
subtitle: "Dernière modification : `r format(Sys.time(), '%d %B, %Y')`"
author: "Romuald - Laëtitia"
date: "27/01/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Résumé du code* : ce script permet d'analyser les données du point scATACseq sur des cellules cultivées pendant 24h en MP.  
La première partie correspond à une prise en main de la manipulation des objets Seurat.  
La deuxième partie permet de vérifier la qualité des données récupérées.  
**Code en partie inspiré de** : https://satijalab.org/signac/articles/pbmc_vignette.html 

```{r Libraries, message=F, echo=FALSE, warning=FALSE, results='hide'}

library(Signac) # addon to Seurat library to work with scATACseq data
library(Seurat)
library(GenomeInfoDb) # Database with genome information
library(EnsDb.Hsapiens.v86) # v.86= hg38 | v.75=hg19
library(ggplot2)
library(patchwork)
library(readr)
library(dplyr)
library(cowplot)
library(clusterProfiler) # to perform gene ontology analysis
library(tidyverse) # to use mutate_all
library(kableExtra)

```

```{r Working directories}

dir_git = "~/Bureau/sc_ATAC_analysis/Git_sc_ATAC_analysis/"
dir_input = "~/Bureau/sc_ATAC_analysis/Git_sc_ATAC_analysis/data/scATAC_raw_data/ATAC_Ctrl_MP/"
dir_output = "~/Bureau/sc_ATAC_analysis/Git_sc_ATAC_analysis/exp/complete_Seurat_procedure/"
# currentDate <- paste0(substr(Sys.Date(), 1,4), substr(Sys.Date(),6,7), substr(Sys.Date(),9, 10))
currentDate = "20220322"
dir.create(path = paste0(dir_output, currentDate))

# à effacer quand code fini (redondant avec partie préprocessing)
dims_choice = "2:30"
dims_choice_char = "2-30"
```

<!--*************************************************************************-->
<br><br><br>
<!--*************************************************************************-->

# .Mise en forme des données en Objet Seurat

```{r, Create the Object, message=F, warning=F}

counts <- Seurat::Read10X_h5(filename = paste0(dir_input, "filtered_peak_bc_matrix.h5"))

# Sequencing information
metadata <- read.csv(
  file = paste0(dir_input, "singlecell.csv"),
  header = TRUE,
  row.names = 1
)

chrom_assay <- CreateChromatinAssay(
  counts = counts,
  sep = c(":", "-"),
  genome = 'hg38',
  fragments = paste0(dir_input, "fragments.tsv.gz"), # tous les reads/cell, où ils tombent et combien de fois ils ont été trouvés (même non assignés)
  min.cells = 100,
  min.features = 200
)

seurat_obj <- CreateSeuratObject(
  counts = chrom_assay,
  assay = "peaks",
  meta.data = metadata)

# Check for the assays informations
seurat_obj[['peaks']]

# Remove unused objects
rm(chrom_assay, counts, metadata)
```

```{r, Basic functions for information access}

###############
## METADATA ##
###############

# Cells(x = seurat_obj) # Cell name
# rownames(x = seurat_obj) # Peak name
# ncol(x = seurat_obj) # nb of cell
# nrow(x = seurat_obj) # nb of peaks

# Set identity classes
Idents(object = seurat_obj) <- "MP"

##################
## Downsampling ##
##################

# Downsample the number of cells per identity class
# Creation of a downsampled object to test and develop the code
# seurat_obj_dwn = subset(x = seurat_obj, downsample = 500)
# # Do we work on all seurat_object or downsampled one ?
# seurat_obj = seurat_obj_dwn
# rm(seurat_obj_dwn)

##########################################
## cell embedding and feature loadings ##
########################################

# Return all reductions computed for each assay
# seurat_obj@reductions

# Info about one specific reduction (here we test lsi reduction)
# seurat_obj@reductions$lsi
# seurat_obj[["lsi"]]

## Access to data generated by the  dimension reduction

# Cell embeddings
# head(Embeddings(seurat_obj, reduction = "lsi"))[,1:3]

# Feature loadings
# head(Loadings(object = seurat_obj, reduction = "lsi"))[,1:3]

########################
## expression matrix ##
#######################

# Retrieve or set data in an expression matrix ('counts', 'data', and 'scale.data')
# GetAssayData(object = seurat_obj, slot = "counts") # Access the count matrix (peaks/cell)

```

```{r, Add annotation file, warning=FALSE, message=FALSE}

# Needed for TSS Enrichment (quality control function)
# Extract gene annotations from EnsDb and attach it to the seurat object (all the BDD annotations)
# This will allow downstream function to extract gene information directly from the object instead of remote request to a server
annotations <- GetGRangesFromEnsDb(ensdb = EnsDb.Hsapiens.v86)

# change to UCSC style
seqlevelsStyle(annotations) = "UCSC"

# add the gene information to the seurat object
Annotation(seurat_obj) = annotations

# Extract informations from BDD annotations
table(mcols(Annotation(seurat_obj))$type)

```

```{r, Add metadata in Grange (peak name and annotation), message=FALSE, warning=F}

# Load Annotation file and extract annotations levels
all_annotations = readRDS(paste0(dir_git, "/data/Annotation_TSS_pm1kb_int_ex_53utr_ctcf_cpg_woThisto_FANTOM5_prom_gr.rds"))
annotations_types = levels(factor(all_annotations$annotation))

# First a matrix is created filled with FALSE and added to the Grange
metadata = matrix(FALSE, ncol = length(annotations_types), nrow = length(seurat_obj@assays$peaks@ranges))
colnames(metadata) = annotations_types
mcols(seurat_obj@assays$peaks@ranges) = metadata 

# for each of the annotations types an overlap is calculated and used to assigned the peak as TRUE when overlapping with the annotation
for (i in 1:ncol(metadata)){
  sub_annot = all_annotations[all_annotations$annotation == annotations_types[i]]
  overlaps = findOverlaps(seurat_obj@assays$peaks@ranges, sub_annot)
  mcols(seurat_obj@assays$peaks@ranges)[queryHits(overlaps),i] = TRUE
}

colnames(mcols(seurat_obj@assays$peaks@ranges)) = case_when(colnames(mcols(seurat_obj@assays$peaks@ranges)) == "3' UTR" ~ "UTR3P",
                                colnames(mcols(seurat_obj@assays$peaks@ranges)) == "5' UTR" ~ "UTR5P",
                                colnames(mcols(seurat_obj@assays$peaks@ranges)) == "CpG Island" ~ "CpG",
                                colnames(mcols(seurat_obj@assays$peaks@ranges)) == "CTCF" ~ "CTCF",
                                colnames(mcols(seurat_obj@assays$peaks@ranges)) == "EXON" ~ "Exons",
                                colnames(mcols(seurat_obj@assays$peaks@ranges)) == "FANTOM5_promoter" ~ "FANTOM5_promoter",
                                colnames(mcols(seurat_obj@assays$peaks@ranges)) == "INTRON" ~ "Introns",
                                colnames(mcols(seurat_obj@assays$peaks@ranges)) == "Promoter_+-1000"  ~ "TSS_mp1kb")

mcols(seurat_obj@assays$peaks@ranges) = as_tibble(mcols(seurat_obj@assays$peaks@ranges)) %>%
  dplyr::mutate(Intergenic = ifelse(UTR3P == FALSE & 
                                    UTR5P == FALSE & 
                                    Exons == FALSE & 
                                    Introns == FALSE & 
                                    FANTOM5_promoter == FALSE & 
                                    TSS_mp1kb == FALSE, TRUE, FALSE)) %>%
  dplyr::mutate(CpG_Intergenic = ifelse(Intergenic == TRUE & CpG == TRUE, TRUE, FALSE)) %>%
  dplyr::mutate(CpG_Intergenic = ifelse(Intergenic == TRUE & CpG == TRUE, TRUE, FALSE)) %>%
  dplyr::mutate(CTCF_Intergenic = ifelse(Intergenic == TRUE & CTCF == TRUE, TRUE, FALSE)) %>%
  dplyr::mutate(CTCF_in_intron = ifelse(Introns == TRUE & CTCF == TRUE, TRUE, FALSE)) %>%
  dplyr::mutate(CTCF_in_exon = ifelse(Exons == TRUE & CTCF == TRUE, TRUE, FALSE))

# Ajout du nom du peak pour avoir une correspondance avec la matrix count de chromatin assay
# Attention ! Bug un peu, j'ai du le lancer deux fois pour que la colonne s'ajoute... pk ?
mcols(seurat_obj@assays$peaks@ranges)$peaks_name = paste0(seurat_obj@assays$peaks@ranges@seqnames, "-", seurat_obj@assays$peaks@ranges@ranges)

# Visualize grange with new metadata columns
seurat_obj@assays$peaks@ranges

# Clean working space
rm(annotations, all_annotations, sub_annot, metadata, annotations_types, overlaps, i)

```

```{r, Clean Seurat Grange from non standard chromosome names, eval = FALSE}

# ATTENTION !!! La fonction keepStandardChromosome ne s'applique que sur le Grange stocké dans l'objet seurat.
# On se retrouve alors avec un nombre différent de peaks dans le grange et dans la matrice de count du chromatin assay.
# Il faut donc égaliser le nombre de peak à la main sinon on a des erreurs lors du clustering (subscript is a logical vector with out-of-bounds TRUE values)
# https://www.biostars.org/p/9466838/
# https://kasperdanielhansen.github.io/genbioconductor/html/GenomicRanges_seqinfo.html
# https://web.mit.edu/~r/current/arch/i386_linux26/lib/R/library/GenomeInfoDb/html/seqinfo.html


#### Visualize grange object and chromosomes seqnames before cleaning
print(paste0("Peaks number in grange : ", nrow(as.data.frame(seurat_obj@assays$peaks@ranges))))
print(unique(as.vector(seurat_obj@assays$peaks@ranges@seqnames)))
print(paste0("Peaks number in matrix count of chromatin assay : ", nrow(seurat_obj)))

#### Keep only standard chromosomes names in grange object (1-22, X, Y, M) : option coarse, peaks with non standard chromosome name are remove
seurat_obj@assays$peaks@ranges = keepStandardChromosomes(seurat_obj@assays$peaks@ranges, pruning.mode = "coarse")
print(paste0("Peaks number in grange : ", nrow(as.data.frame(seurat_obj@assays$peaks@ranges))))
print(unique(as.vector(seurat_obj@assays$peaks@ranges@seqnames)))
print(paste0("Peaks number in matrix count of chromatin assay : ", nrow(seurat_obj)))

#### Keep same list of peaks in matrix count of chromatin assay
list_peak_clean = seurat_obj@assays$peaks@ranges$peaks_name
table(rownames(seurat_obj) %in% list_peak_clean) # il faut enlever les false
seurat_obj = subset(seurat_obj, features = list_peak_clean) # attention, fonctionne ici car on a un seul assay

# # Visualize grange object and chromosomes seqnames after cleaning
print(paste0("Peaks number in grange : ", nrow(as.data.frame(seurat_obj@assays$peaks@ranges))))
print(unique(as.vector(seurat_obj@assays$peaks@ranges@seqnames)))
print(paste0("Peaks number in matrix count of chromatin assay : ", nrow(seurat_obj)))
# Passage d'un Grange à 165 599 features à 165 559 features (=peaks) => 40 peaks ont été enlevés (très peu donc pas de biais)

```

```{r, Save FACULTATIF}
saveRDS(object = seurat_obj, file = paste0(dir_output, currentDate, "/seurat_obj_annot.rds")) 
```


<!--*************************************************************************-->
<br><br><br>
<!--*************************************************************************-->

# .Contrôle qualité des données de l'échantillon

```{r, TSS Enrichment, results = 'hold', fig.width=6, fig.height=4}

# compute TSS enrichment score per cell and add it to meta.data in TSS.enrichment column
seurat_obj <- TSSEnrichment(object = seurat_obj, fast = FALSE)

# Compute a new column in meta.data, based on TSS.enrichment column
seurat_obj$high.tss <- ifelse(seurat_obj$TSS.enrichment > 2, 'High', 'Low')

# Plot based on TSS.enrichment, and group according high.tss column
plot_quality_tss = TSSPlot(seurat_obj, group.by = 'high.tss') + NoLegend()
plot_quality_tss

# Save and clean working space
ggsave(plot = plot_quality_tss, filename = paste0(dir_output, currentDate, "/plot_quality_tss.png"))
rm(plot_quality_tss)
```

```{r, Nucleosome Signal, results = 'hold', fig.width=12, fig.height=4}

# Compute nucleosome signal score per cell and add it to meta.data in nucleosome_signal column
seurat_obj <- NucleosomeSignal(object = seurat_obj)

# Compute a new column in meta.data, based on nucleosome_signal column
seurat_obj$nucleosome_group <- ifelse(seurat_obj$nucleosome_signal > 4, 'NS > 4', 'NS < 4')

# Plot based on nucleosome_signal, and group according nucleosome_group column
plot_quality_nucl = FragmentHistogram(object = seurat_obj, group.by = 'nucleosome_group')
plot_quality_nucl

# Save and clean working space
ggsave(plot = plot_quality_nucl, filename = paste0(dir_output, currentDate, "/plot_quality_nucl.png"), width = 12)
rm(plot_quality_nucl)

```

```{r, QC plots, results = 'hold', fig.width=16, fig.height=6}

# compute percentage of reads in peaks for each cells
seurat_obj$pct_reads_in_peaks <- seurat_obj$peak_region_fragments / seurat_obj$passed_filters * 100
# peak_region_fragments of a cell = number of reads assigned to the peak studied 

# Violin plots for QC
plot_quality_vln = VlnPlot(
  object = seurat_obj,
  features = c('pct_reads_in_peaks', 'peak_region_fragments', 'TSS.enrichment', 'nucleosome_signal'),
  pt.size = 0.1,
  ncol = 5
)
plot_quality_vln

# Save and clean working space
ggsave(plot = plot_quality_vln, filename = paste0(dir_output, currentDate, "/plot_quality_vln.png"), width = 16, height = 6)
rm(plot_quality_vln)

```

```{r, Save FACULTATIF, eval = FALSE}
saveRDS(object = seurat_obj, file = paste0(dir_output, currentDate, "/seurat_obj_qc.rds")) 
```

<!--*************************************************************************-->
<br><br><br>
<!--*************************************************************************-->

# .Préproccessing des données : normalisation et réductions de dimensions

```{r, LOAD FACULTATIF, eval = FALSE}
seurat_obj = readRDS(file = paste0(dir_output, currentDate, "/seurat_obj_qc.rds")) 
```

```{r, Normalization, message=F, warning=F, results = 'hold', fig.width=16, fig.height=6}

# Normalization: term frequency-inverse document frequency (TF-IDF) normalization. 
# Two-step normalization procedure, that both normalizes across cells to correct for differences in cellular sequencing depth, and across peaks to give higher values to more rare peaks.
seurat_obj <- RunTFIDF(seurat_obj)

# Choose to use only the top n% of features (peaks) for dimensional reduction
# Can also remove features present in less than n cells
# Set qXX to only select the top 90% features (peaks)
# Features used for dimensional reduction are automatically set as VariableFeatures() by this function.
seurat_obj <- FindTopFeatures(seurat_obj, min.cutoff = 'q10') # Drop the 10 lowest %

# Dimension reduction: singular value decomposition (SVD) on the TD-IDF matrix
# It automatically uses the features (peaks) selected above. 
# This returns a reduced dimension representation of the object 
# (You can think of this as analogous to the output of PCA).
seurat_obj <- RunSVD(seurat_obj)

## ATTENTION : The combined steps of TF-IDF followed by SVD are known as latent semantic indexing (LSI)
# The 1st LSI component often captures sequencing depth (technical variation) rather than biological variation
# If this is the case (< - 0.7 or > 0.7), then discard it for further analysis
plot_dim_depth = DepthCor(object = seurat_obj, assay ="peaks", reduction = "lsi", n = NULL) + 
  geom_hline(yintercept = -0.7, linetype = "dashed", color = "red") +
  geom_hline(yintercept = + 0.7, linetype = "dashed", color = "red")

# We play on ylim to manually remove lsi1 and visualize the elbow
plot_dim_elb = ElbowPlot(object = seurat_obj, ndims = 50, reduction = "lsi") + 
    ylim(0.2, 3) +
    theme(plot.background = element_rect(fill = "white"))

plot_dim_depth | plot_dim_elb

# Choice of working dimensions
dims_choice = c(2:30)
dims_choice_char = "2-30"

# Save and clean working directory
ggsave(plot = plot_dim_depth | plot_dim_elb, 
       filename = paste0(dir_output, currentDate, "/plot_preprocess_dim.png"), 
       width = 18, height = 6)
rm(plot_dim_elb, plot_dim_depth)
```
fichier downsampled : Coude observé entre 5 et 10 dimensions. pour la suite, on travaille avec 10 dimensions. 
All data set : coude observé entre 20 et 30 dimensions, on choisit d'utiliser 30 dimensions.
Quand doute sur le nombre de dims à conserver : il vaut mieux en prendre plus que pas assez

```{r, Umap with diff resolution, results = 'hold', fig.width=16, fig.height=10}

# Compute another reduction (commonly used for RNAseq) : UMAP
  ## Of note, usually UMAP is based on PCA dimension reduction, but here it's on lsi
  ## Dump the first dimension according to the graph above
seurat_obj <- RunUMAP(object = seurat_obj, reduction = 'lsi', dims = dims_choice)
# => Now another reduction has been added to seurat_obj@reduction : "umap"

# Constructing the K-nearest neighbor (KNN) graph (by default)
# Edges drawn between cells with similar gene expression patterns. 
# Then, it attempts to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’.
seurat_obj <- FindNeighbors(object = seurat_obj, reduction = 'lsi', dims = dims_choice)
# => This function adds a "graph" named peaks_snn in seurat_obj@graphs

# Based on the current default assay
## Resolution = 0.8
## Algorithm = 1 = Louvain
seurat_obj <- FindClusters(object = seurat_obj, algorithm = 3)
# => This function adds 2 new columns to meta.data : seurat_clusters AND peaks_snn_res.0.8. There are equivalent
# => If the name of algorithm is changed, then this 2 columns are replaced and a little bit different from previously

# Try different resolution argument that sets the “granularity” of the downstream clustering
for (res in c(0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.8, 1)) {
    seurat_obj <- FindClusters(
      object = seurat_obj, 
      graph.name = "peaks_snn", 
      resolution = res, 
      algorithm = 3)
}

# => Recalculate the clusters for different resolution and store the results in new columns in meta.data
# names(seurat_obj[[]]) # to see the columns added
plot_resolution = plot_grid(
  ncol = 3, 
  nrow = 3,
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.01") + ggtitle("Resolution_0.01"),
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.02") + ggtitle("Resolution_0.02"),
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.05") + ggtitle("Resolution_0.05"),
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.1") + ggtitle("Resolution_0.1"),
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.2") + ggtitle("Resolution_0.2"),
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.5") + ggtitle("Resolution_0.5"),
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.8") + ggtitle("Resolution_0.8"),
  DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.1") + ggtitle("Resolution_1"))
plot_resolution

# Save and clean working space
ggsave(plot = plot_resolution, 
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_resolution.png"), 
       width = 18, height = 10)

# Save figure for article : res 0.05, pdf format to be modified with inkscape
ggsave(plot = DimPlot(seurat_obj, reduction = "umap", group.by = "peaks_snn_res.0.05") + ggtitle("Resolution_0.05"),
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_res0,05.pdf"), 
       width = 14, height = 6)

rm(plot_resolution, res)
```

=> pk algo = 3 ???
Commentaire : résolution au dessus de 0.05 ne sépare pas bien les clusters. 
On choisit des valeurs en dessous. => se renseigner pour voir si c'est mieux de prendre la plus élevée possible ou pas 

```{r, Umap with diff kmean, results = 'hold', fig.width=16, fig.height=8}

# Same approach but compare with k means method

for (k in c(2, 3, 4, 5, 10)) {
     seurat_obj@meta.data[, paste0("kmeans_", k)] <- kmeans(x = seurat_obj@reductions[["lsi"]]@cell.embeddings, centers = k, nstart = 100)$cluster
 }
 
plot_kmean = plot_grid(
   ncol = 3,
    DimPlot(seurat_obj, reduction = "umap", group.by = "kmeans_2") + ggtitle("kmeans_2"), 
    DimPlot(seurat_obj, reduction = "umap", group.by = "kmeans_3") + ggtitle("kmeans_3"),
    DimPlot(seurat_obj, reduction = "umap", group.by = "kmeans_4") + ggtitle("kmeans_4"),
    DimPlot(seurat_obj, reduction = "umap", group.by = "kmeans_5") + ggtitle("kmeans_5"), 
    DimPlot(seurat_obj, reduction = "umap", group.by = "kmeans_10") + ggtitle("kmeans_10"))
plot_kmean

# Save plot and clean working space
ggsave(plot = plot_kmean, 
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_kmean.png"), 
       width = 18, height = 8)
rm(plot_kmean, k)

```

```{r, Save FACULTATIF, eval = FALSE}
saveRDS(object = seurat_obj, file = paste0(dir_output, currentDate, "/seurat_obj_preprocess_dim", dims_choice_char,".rds")) 
```


<!--*************************************************************************-->
<br><br><br>
<!--*************************************************************************-->



# .Association des peaks à l'activité du gène le plus proche

```{r, Load FACULTATIF, eval = FALSE}
seurat_obj = readRDS(file = paste0(dir_output, currentDate, "/seurat_obj_preprocess_dim", dims_choice_char,".rds")) 
```

```{r, Gene activity matrix}

# Transfo les données ATAC en équivalent RNA : convertit le nombre de reads comme si c'était des UMI

# Create a gene activity matrix based on the number of reads mapping to each in gene (gene body +2kb upstream)
gene.activities <- GeneActivity(seurat_obj)
# features argument : if NULL use all protein-coding genes in the annotations stored in the object

# add the gene activity matrix to the Seurat object as a new assay  
seurat_obj[['RNA']] <- CreateAssayObject(counts = gene.activities)

# The count normalizes it
seurat_obj <- NormalizeData(
  object = seurat_obj,
  assay = 'RNA',
  normalization.method = 'LogNormalize',
  scale.factor = median(seurat_obj$nCount_RNA)
)
# => Adds normalized data to seurat_obj[['RNA]]@data slot

```

```{r, Gene activity plot, results = 'hold', fig.width=16, fig.height=12}

DefaultAssay(seurat_obj) <- 'RNA'

seurat_obj <- FindVariableFeatures(object = seurat_obj, assay = 'RNA', nfeatures = 100)
# Adds a slot@var.features

# On garde la reduction PCA de ATACseq donc les mêmes clusters
# On "colle" par dessus l'info des gènes exprimés
# Possibilité de regarder un gène particulier !
plot_varfeature = FeaturePlot(
  object = seurat_obj,
  features = seurat_obj[['RNA']]@var.features[1:10],
  pt.size = 0.1,
  max.cutoff = 'q95',
  ncol = 3
)
plot_varfeature

# Mise en évidence de peaks au niveau des gènes et promoteurs des 11 facteurs de transcription
list_12TF = c('SMAD6', 'TAL1', 'HHEX', 'ZFPM1', 'FLI1', 'CBFA2T3', 'SPI1', 'ERG', 'RUNX1', 'GATA1', 'GATA2', 'CBFB')
plot_11TF = FeaturePlot(
  object = seurat_obj,
  features = list_12TF,
  pt.size = 0.1,
  max.cutoff = 'q95',
  ncol = 3,
  cols = c('#1873CC','#1798E5','#00BFFF','#4AC596','#00CC00','#A2E700','#FFFF00','#FFD200','#FFA500')
)
plot_11TF

# Save plots and clean working space
ggsave(plot = plot_varfeature, 
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_varfeature.png"), 
       width = 18, height = 16)
ggsave(plot = plot_11TF, 
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_plot11TF.pdf"), 
       width = 18, height = 20)
rm(gene.activities, plot_varfeature, plot_11TF)

```




```{r, Save FACULTATIF}
saveRDS(object = seurat_obj, file = paste0(dir_output, currentDate, "/seurat_obj_geneact_dim", dims_choice_char, ".rds")) 
```


<!--*************************************************************************-->
<br><br><br>
<!--*************************************************************************-->



# .Investigation sur les clusters obtenus 

```{r, Load FACULTATIF, eval = FALSE}
seurat_obj = readRDS(file = paste0(dir_output, currentDate, "/seurat_obj_geneact_dim2-30.rds")) 
```

```{r, Change DefaultAssay and choose resolution}

# Change back to working with peaks instead of gene activities
DefaultAssay(seurat_obj) <- 'peaks'

# Choose working resolution
res = "res.0.05"
meta_col = paste0("peaks_snn_", res)
Idents(seurat_obj) = (seurat_obj@meta.data)[,meta_col]

```

```{r, Subset seurat_obj based on cluster, eval = FALSE}

# Subset seurat obj to create one object per cluster
for (i in 1:length(levels((seurat_obj@meta.data)[,meta_col])) ) {

  # Extract cluster number
  clust = levels((seurat_obj@meta.data)[,meta_col])[i]
  print(paste("Cells extraction for clust ", clust))
  # Create subset of seurat object with cells from clust x
  expr = FetchData(object = seurat_obj, vars = meta_col)
  seurat_clust = seurat_obj[, which(expr == clust)]                       # ligne qui prend du temps
  # Check if the subset was correctly done
  print(table((seurat_clust@meta.data)[,meta_col]))

  # Extract peak count matrix of clust x from general seurat object
  print("Matrix count extraction")
  tab_clust = as.data.frame(GetAssayData(seurat_clust, slot = "data"))    # ligne qui prend du temps

  # Save object
  saveRDS(tab_clust, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_matrix_count_clust", clust, ".rds"))
  saveRDS(seurat_clust, file = paste0(dir_output, currentDate, "/seurat_clust", clust, "_dim", dims_choice_char, "_", res, ".rds"))

}

```

```{r, Peaks distribution per cell across clusters - tabs creation}

# https://github.com/satijalab/seurat/issues/1053

# Create dataframe with summary of peaks per cell and/or per annotation
tab_distripeaks_clust = data.frame()
tab_bulkpeaks_clust = data.frame()
  
for ( i in 1:length(levels((seurat_obj@meta.data)[,meta_col])) ) {
  
  # Extract cluster number
  clust = levels((seurat_obj@meta.data)[,meta_col])[i]
  print(paste("Cells extraction for clust ", clust))
  # Load subset of seurat object with cells from clust x and corresponding matrix count
  seurat_clust = readRDS(paste0(dir_output, currentDate, "/seurat_clust", clust, "_dim", dims_choice_char, "_", res, ".rds"))
  print("Load matrix count")
  tab_clust = readRDS(paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_matrix_count_clust", clust, ".rds"))
  # Transform matrix count into logical
  tab_clust = tab_clust %>% mutate_all(as.logical)
  
  # Extract peaks_name according to genomic annotation
  print("Calcul peaks vs genomic annotation")
  peaks_name_list = list(
    total_peaks = seurat_clust@assays$peaks@ranges$peaks_name,
    peaks_FANTOM5_promoter = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$FANTOM5_promoter == TRUE])$peaks_name,
    peaks_UTR3P = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$UTR3P == TRUE])$peaks_name,
    peaks_UTR5P = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$UTR5P == TRUE])$peaks_name,
    peaks_CpG = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CpG == TRUE])$peaks_name,
    peaks_CTCF = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF == TRUE])$peaks_name,
    peaks_Exons = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$Exons == TRUE])$peaks_name,
    peaks_Introns = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$Introns == TRUE])$peaks_name,
    peaks_TSS_mp1kb = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$TSS_mp1kb == TRUE])$peaks_name,
    peaks_Intergenic = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$Intergenic == TRUE])$peaks_name,
    peaks_CpG_Intergenic = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CpG_Intergenic == TRUE])$peaks_name,
    peaks_CTCF_Intergenic = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF_Intergenic == TRUE])$peaks_name,
    peaks_CTCF_in_intron = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF_in_intron == TRUE])$peaks_name,
    peaks_CTCF_in_exon = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF_in_exon == TRUE])$peaks_name
    )

  # Calculate number of peaks total per annotation and per cell per annotation
  temp_distripeaks = lapply(peaks_name_list, function(x) {
    tab_filtered = tab_clust %>% dplyr::filter(row.names(tab_clust) %in% unlist(x))
    tab_calc = data.frame(colSums(tab_filtered)) 
    tab_calc = tab_calc %>% tibble::rownames_to_column(var = "cell")})
  temp_distripeaks = bind_rows(temp_distripeaks, .id = "peaks_category") %>% dplyr::mutate(clust = clust)
  colnames(temp_distripeaks) = c("peaks_category", "cell", "total_nbpeaks_percell", "clust")
  
  temp_bulkpeaks = data_frame(annotation = names(peaks_name_list), total_nbpeaks = as.numeric(lapply(peaks_name_list, length))) %>% 
    dplyr::mutate(clust = clust, .before = "total_nbpeaks")
  
  # Bind in general tab
  tab_bulkpeaks_clust = rbind(tab_bulkpeaks_clust, temp_bulkpeaks)
  tab_distripeaks_clust = rbind(tab_distripeaks_clust, temp_distripeaks)

}

# Add statistical information
tab_distripeaks_stat = tab_distripeaks_clust %>%
  dplyr::group_by(clust, peaks_category) %>%
  dplyr::mutate(nbcells_clust = n(),
                median_nbpeaks_percell = median(total_nbpeaks_percell),
                mean_nbpeaks_percell = round(mean(total_nbpeaks_percell)),
                max_nbpeaks_percell = max(total_nbpeaks_percell),
                min_nbpeaks_percell = min(total_nbpeaks_percell),
                var_nbpeaks_percell = round(sd(total_nbpeaks_percell))) %>%
  dplyr::mutate(percent_cell_clust = round((nbcells_clust/ncol(seurat_obj))*100)) %>%
  dplyr::ungroup() %>%
  dplyr::select(peaks_category, clust, nbcells_clust, percent_cell_clust, median_nbpeaks_percell, 
                mean_nbpeaks_percell, max_nbpeaks_percell, min_nbpeaks_percell, var_nbpeaks_percell) %>%
  dplyr::distinct()

# Save dataframes and clean working space
write_csv2(tab_bulkpeaks_clust, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_bulkpeaks.csv"))
write_csv2(tab_distripeaks_clust, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_distripeaks.csv"))
write_csv2(tab_distripeaks_stat, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_distripeaks_stat.csv"))
rm(temp_bulkpeaks, temp_distripeaks, peaks_name_list, clust, seurat_clust, i, expr, tab_clust)

```

```{r, Peaks distribution per cell across clusters - visualization, results = 'hold', fig.width=20, fig.height=6}

# load files (facultatif)
# tab_bulkpeaks_clust = read_csv2(paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_bulkpeaks.csv"))
# tab_distripeaks_clust = read_csv2(paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_distripeaks.csv"))
# tab_distripeaks_stat = read_csv2(paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_distripeaks_stat.csv"))

# Visualize output tab
tab_distripeaks_clust %>% 
  kable(caption = res) %>% 
  kable_styling()  %>%
  scroll_box(height = "250px", width = "100%")

tab_distripeaks_stat %>% 
  kable(caption = res) %>% 
  kable_styling()  %>%
  scroll_box(height = "250px", width = "100%")

tab_bulkpeaks_clust %>%
  kable(caption = res) %>% 
  kable_styling() %>%
  scroll_box(height = "250px", width = "100%")

# Histogram : nbpeaks per annotation per cluster
plot_bulkpeak = ggplot(tab_bulkpeaks_clust, aes(x=annotation, y=total_nbpeaks, fill=clust)) +
  geom_bar(stat="identity", position=position_dodge()) +
  ylab(label = "TOTAL PEAK NUMBER IN CLUSTER") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        axis.title.x = element_blank())
plot_bulkpeak

# Distribution : nbpeaks per cell per annotation 
tab_plot  = full_join(tab_distripeaks_clust, tab_distripeaks_stat, by = c("peaks_category", "clust"))
tab_plot$clust = as.factor(tab_plot$clust)
plot_distripeak = ggplot(tab_plot, aes(x=total_nbpeaks_percell, fill=clust)) +
  geom_histogram(bins = 50, color = "black", alpha = 0.5) +
  geom_vline(aes(xintercept = median_nbpeaks_percell, col=clust), linetype = "dashed", size = 1) +
  ggtitle(label = paste0("Peaks' distribution per cell according to cluster (with median) - ", res, " !!! Different scales !!!")) +
  ylab(label = "CELL COUNT") +
  xlab("NBPEAKS PER CELL") +
  facet_wrap(facets = .~peaks_category, scales = "free") 
plot_distripeak

# Save objects
ggsave(plot = plot_bulkpeak,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_hist_peak_annot_clust.png"),
       width = 14, height = 6)
ggsave(plot = plot_distripeak,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_distri_peak_annot_clust.png"),
       width = 16, height = 10)

# Save plot for article 
plot_article_total = ggplot(tab_plot %>% filter(peaks_category == "total_peaks"), aes(x=total_nbpeaks_percell, fill=clust)) +
  geom_histogram(bins = 50, color = "black", alpha = 0.5) +
  geom_vline(aes(xintercept = median_nbpeaks_percell, col=clust), linetype = "dashed", size = 1) +
  ylab(label = "CELL COUNT") +
  xlab(label = "NBPEAKS PER CELL") +
  ggtitle(label = "TOTAL PEAKS")
plot_article_prom = ggplot(tab_plot %>% filter(peaks_category == "peaks_FANTOM5_promoter"), aes(x=total_nbpeaks_percell, fill=clust)) +
  geom_histogram(bins = 50, color = "black", alpha = 0.5) +
  geom_vline(aes(xintercept = median_nbpeaks_percell, col=clust), linetype = "dashed", size = 1) +
  ylab(label = "CELL COUNT") +
  xlab(label = "NBPEAKS PER CELL") +
  ggtitle(label = "PEAKS SPANNING PROMOTERS")
plot_article_intergenic = ggplot(tab_plot %>% filter(peaks_category == "peaks_Intergenic"), aes(x=total_nbpeaks_percell, fill=clust)) +
  geom_histogram(bins = 50, color = "black", alpha = 0.5) +
  geom_vline(aes(xintercept = median_nbpeaks_percell, col=clust), linetype = "dashed", size = 1) +
  ylab(label = "CELL COUNT") +
  xlab(label = "NBPEAKS PER CELL") +
  ggtitle(label = "PEAKS FROM INTERGENIC REGION")

ggsave(plot = plot_article_total | plot_article_prom | plot_article_intergenic,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_distri_peak_annot_clust_article.pdf"),
       width = 16, height = 4)

```

```{r, Peaks distribution per cell across clusters - Focus Clust0_1 Inter_Prom, results = 'hold', fig.width=20, fig.height=10}

# Calculate difference between median nbpeaks per cell in clust 1 and in clust 0 for each annotation category
tab_delta = tab_plot %>% 
  dplyr::select(peaks_category, clust, median_nbpeaks_percell) %>% 
  dplyr::filter(clust %in% c("0", "1")) %>%
  dplyr::distinct() %>%
  dplyr::group_by(peaks_category) %>%
  dplyr::mutate(diff_clust1_clust0 = median_nbpeaks_percell[clust == "0"] - median_nbpeaks_percell[clust == "1"])

tab_delta %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(height = "250px", width = "100%")
  
# Visualize plot woth only promoter and intergenic
tab_inter_prom = tab_plot %>% dplyr::filter(peaks_category %in% c("peaks_FANTOM5_promoter", "peaks_Intergenic"))
plot_distri_interprom = ggplot(tab_inter_prom, aes(x=total_nbpeaks_percell, fill=clust)) +
  geom_histogram(bins = 50, color = "black", alpha = 0.5) +
  geom_vline(aes(xintercept = median_nbpeaks_percell, col=clust), linetype = "dashed", size = 1) +
  ggtitle(label = paste0("Peaks' distribution per cell according to cluster (with median) - ", res)) +
  ylab(label = "CELL COUNT") +
  xlab("NBPEAKS PER CELL") +
  facet_wrap(facets = .~peaks_category)
plot_distri_interprom

# Save object and clean working space
ggsave(plot = plot_distri_interprom,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_distri_peak_annot_clust_zoominterprom.png"),
       width = 16, height = 10)
write_csv2(tab_delta, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_delta_clust1_clust0.csv"))
rm(tab_bulkpeaks_clust, tab_distripeaks_clust, tab_distripeaks_stat, tab_plot, plot_distripeak, plot_bulkpeak, tab_inter_prom, tab_delta, plot_distri_interprom)

```

```{r, Verification reads number}

# somme des reads : est-ce que toutes les cellules versus cellules clust0 versus cellules clust1 ont bien un nombre de reads différents pour les peaks ?

# Extract matrix count for each cells 
tab_all = as.data.frame(GetAssayData(seurat_obj, slot = "data")) 
tab_clust0 = readRDS(paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_matrix_count_clust0.rds"))
tab_clust1 = readRDS(paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_matrix_count_clust1.rds"))
# On a bien trois tableaux avec le même nombre de lignes (peaks) mais qui diffèrent par leur nombre de colonnes (cellules)

# Compare matrix count
tab_compare = data.frame(nbreads_allcells = rowSums(tab_all),
                         nbreads_clust0 = rowSums(tab_clust0),
                         nbreads_clust1 = rowSums(tab_clust1))  %>% 
  tibble::rownames_to_column(var = "peak_name")

# Save object and clean workspace 
saveRDS(tab_all, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_matrix_count.rds"))
write_csv2(tab_compare, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_nbreads_clust.csv"))
rm(tab_all, tab_clust0, tab_clust1, tab_compare)

```

```{r, Sharing peaks in cell across clusters, results = 'hold', fig.width=6, fig.height=16}

tab_districell_clust = data.frame()

for ( i in 1:length(levels((seurat_obj@meta.data)[,meta_col])) ) {
  
  # Extract cluster number
  clust = levels((seurat_obj@meta.data)[,meta_col])[i]
  print(paste("Cells extraction for clust ", clust))
 # Load seurat object subset on clust x 
  seurat_clust = readRDS(paste0(dir_output, currentDate, "/seurat_clust", clust, "_dim", dims_choice_char, "_", res, ".rds"))
 # Load matrix count for cells from clust x 
  tab_clust = readRDS(paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_matrix_count_clust", clust, ".rds"))
  tab_clust = tab_clust %>% mutate_all(as.logical)
  
  # Extract peaks_name according to genomic annotation
  peaks_name_list = list(
    total_peaks = seurat_clust@assays$peaks@ranges$peaks_name,
    peaks_FANTOM5_promoter = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$FANTOM5_promoter == TRUE])$peaks_name,
    peaks_UTR3P = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$UTR3P == TRUE])$peaks_name,
    peaks_UTR5P = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$UTR5P == TRUE])$peaks_name,
    peaks_CpG = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CpG == TRUE])$peaks_name,
    peaks_CTCF = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF == TRUE])$peaks_name,
    peaks_Exons = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$Exons == TRUE])$peaks_name,
    peaks_Introns = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$Introns == TRUE])$peaks_name,
    peaks_TSS_mp1kb = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$TSS_mp1kb == TRUE])$peaks_name,
    peaks_Intergenic = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$Intergenic == TRUE])$peaks_name,
    peaks_CpG_Intergenic = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CpG_Intergenic == TRUE])$peaks_name,
    peaks_CTCF_Intergenic = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF_Intergenic == TRUE])$peaks_name,
    peaks_CTCF_in_intron = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF_in_intron == TRUE])$peaks_name,
    peaks_CTCF_in_exon = (seurat_clust@assays$peaks@ranges[seurat_clust@assays$peaks@ranges$CTCF_in_exon == TRUE])$peaks_name
    )

  # Calculate number of peaks total per annotation and per cell per annotation
 temp_districell_clust = lapply(peaks_name_list, function(x) {
    tab_filtered = tab_clust %>% dplyr::filter(row.names(tab_clust) %in% unlist(x))
    tab_calc = data.frame(rowSums(tab_filtered)) 
    tab_calc = tab_calc %>% tibble::rownames_to_column(var = "peak")})
  temp_districell_clust = bind_rows(temp_districell_clust, .id = "peaks_category") %>% dplyr::mutate(clust = clust, nbcells_clust = ncol(tab_clust))
  colnames(temp_districell_clust) = c("peaks_category", "peak", "nbcells_sharing_peak", "clust", "nbcells_clust")
  temp_districell_clust = temp_districell_clust %>% dplyr::mutate(propcells_sharing_peak = round((nbcells_sharing_peak/nbcells_clust)*100))
  tab_districell_clust = rbind(tab_districell_clust, temp_districell_clust)
  
}

tab_districell_stat = tab_districell_clust %>%
  dplyr::group_by(clust, peaks_category) %>%
  dplyr::mutate(median_nbcells_sharing_peak = median(nbcells_sharing_peak),
                mean_nbcells_sharing_peak = round(mean(nbcells_sharing_peak)),
                max_nbcells_sharing_peak = max(nbcells_sharing_peak),
                min_nbcells_sharing_peak = min(nbcells_sharing_peak),
                var_nbcells_sharing_peak = round(sd(nbcells_sharing_peak)),
                median_propcells_sharing_peak = median(propcells_sharing_peak),
                mean_propcells_sharing_peak = round(mean(propcells_sharing_peak)),
                max_propcells_sharing_peak = max(propcells_sharing_peak),
                min_propcells_sharing_peak = min(propcells_sharing_peak),
                var_propcells_sharing_peak = round(sd(propcells_sharing_peak))) %>%
  dplyr::ungroup() %>%
  dplyr::select(peaks_category, clust, median_nbcells_sharing_peak, mean_nbcells_sharing_peak,
                max_nbcells_sharing_peak, min_nbcells_sharing_peak, var_nbcells_sharing_peak,
                median_propcells_sharing_peak, mean_propcells_sharing_peak, max_propcells_sharing_peak, 
                min_propcells_sharing_peak, var_propcells_sharing_peak) %>%
  dplyr::distinct()

# Distribution : nbpeaks per cell per annotation 
tab_plot  = full_join(tab_districell_clust, tab_districell_stat, by = c("peaks_category", "clust"))
tab_plot$clust = as.factor(tab_plot$clust)

legend.grid = c("0" = "cluster 0", "1" = "cluster 1", "2" = "cluster 2", "3" = "cluster 3", "4" = "cluster 4")
plot_districell_grid = ggplot(tab_plot, aes(x=propcells_sharing_peak, fill=clust)) +
  geom_histogram(binwidth = 10, color = "black", alpha = 0.5, position = "identity") +
  geom_vline(aes(xintercept = median_propcells_sharing_peak, col=clust), linetype = "dashed", size = 1) +
  ggtitle(label = paste0("Dashed line correspond to median - ", res, " !!! Different scales !!!")) +
  ylab(label = "NUMBER OF PEAKS CONCERNED") +
  xlab("PROPORTION OF CELLS SHARING A PEAK IN THE CLUSTER") +
  facet_grid(peaks_category ~ clust, labeller = labeller(clust = legend.grid), scales = "free") +
  theme(legend.position = "none")
plot_districell_grid

plot_districell = ggplot(tab_plot, aes(x=propcells_sharing_peak, fill=clust)) +
  geom_histogram(binwidth = 10, aes(color = clust), alpha = 0.2, position = "identity") +
  geom_vline(aes(xintercept = median_propcells_sharing_peak, col=clust), linetype = "dashed", size = 1) +
  ggtitle(label = paste0("Dashed line correspond to median - ", res, " !!! Different scales !!!")) +
  ylab(label = "NUMBER OF PEAKS CONCERNED") +
  xlab("PROPORTION OF CELLS SHARING A PEAK IN THE CLUSTER") +
  facet_grid(peaks_category~., scales = "free") +
  theme(legend.position = "none")
plot_districell

plot_districell_density = ggplot(tab_plot, aes(x=propcells_sharing_peak, fill=clust)) +
  geom_density(aes(col=clust), alpha = 0.3) +
  geom_vline(aes(xintercept = median_propcells_sharing_peak, col=clust), linetype = "dashed", size = 1) +
  ggtitle(label = paste0("Dashed line correspond to median - ", res, " !!! Different scales !!!")) +
  ylab(label = "PROPOTION OF PEAKS CONCERNED") +
  xlab("PROPORTION OF CELLS SHARING A PEAK IN THE CLUSTER") +
  facet_grid(peaks_category~., scales = "free") +
  theme(legend.position = "none")
plot_districell_density

# Save object and clean working space 
ggsave(plot = plot_districell,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_distri_cell_annot_clust.png"),
       width = 6, height = 14)
ggsave(plot = plot_districell_grid,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_distrigrid_cell_annot_clust.png"),
       width = 16, height = 16)
ggsave(plot = plot_districell_density,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_distridensity_cell_annot_clust.png"),
       width = 6, height = 14)
write_csv2(tab_districell_clust, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_districell.csv"))
write_csv2(tab_districell_stat, file = paste0(dir_output, currentDate, "/tab_dim", dims_choice_char, "_", res, "_districell_stat.csv"))
rm(tab_plot, tab_districell_stat, tab_districell_clust, temp_districell_clust, peaks_name_list, clust, tab_clust, seurat_clust, i)
rm(plot_districell_density, plot_districell_grid, plot_districell, legend.grid)

```

```{r, Isolate cluster specific peak}

# sortir la liste de tous les gènes qui ont un peak dans le clust0, dans le clust1, enlever l'intersection et regarder ce qui n'est pas en commun :
  # - sous sampling que les peaks qui tombent dans TSS (refaire FindMarkers ?)
  # - utiliser closest feature sur tous ces peaks par cluster
  # - faire l'exclusion pour sortir la liste particulière de chaque cluster
  # - GO sur les deux listes

# Subset of seurat object to keep only cells from clust0
clust = "0"
seurat_clust0 = readRDS(paste0(dir_output, currentDate, "/seurat_clust", clust, "_dim", dims_choice_char, "_", res, ".rds"))
clust0_gene <- ClosestFeature(seurat_clust0, regions = granges(seurat_clust0)) 
clust0_gene_list = as.vector(clust0_gene$gene_name)

# Subset of seurat object to keep only cells from clust1
clust = "1"
seurat_clust1 = readRDS(paste0(dir_output, currentDate, "/seurat_clust", clust, "_dim", dims_choice_char, "_", res, ".rds"))
clust1_gene <- ClosestFeature(seurat_clust1, regions = granges(seurat_clust1))
clust1_gene_list = as.vector(clust1_gene$gene_name)

# pb : tous les gènes sont représentés dans les deux clusters, il faut s'intéresser aux proportions d'accessibilité
table(clust0_gene_list == clust1_gene_list)

rm(seurat_clust0, clust0_gene, clust0_gene_list, seurat_clust1, clust1_gene, clust1_gene_list, clust)
```

```{r, Isolate cluster specific top 200 peaks - Gene analysis}

# On isole les peaks du clust0 et du clust1 qui sont partagés par le plus de cellules dans le cluster et on compare les listes obtenues 

########### TRAVAIL A PARTIR DES PEAKS DES PROMOTEURS #######################
# Attention !!! On applique ici le filtre sur les peaks pour garder que les promoteurs avant de sélectionner les 200 peaks les plus partagés
# Si on le fait après, ça change beaucoup le nombre de peaks à extraire

# Load (facultatif)
tab_districell_clust = read.csv2(paste0(dir_output, currentDate, "/tab_dim2-30_res.0.05_districell.csv"))

tab_clust0 = tab_districell_clust %>% 
  dplyr::filter(clust == "0") %>%
  dplyr::filter(peaks_category == "peaks_FANTOM5_promoter") %>% 
  dplyr::arrange(desc(nbcells_sharing_peak))  %>%
  dplyr::select(-clust)
# Tab contenant les 200 peaks les plus partagés par les cellules du cluster0
clust0_top200 = head(tab_clust0, 200)
clust0_top200 = as.vector(clust0_top200$peak)

tab_clust1 = tab_districell_clust %>% 
  dplyr::filter(clust == "1") %>%
  dplyr::filter(peaks_category == "peaks_FANTOM5_promoter") %>% 
  dplyr::arrange(desc(nbcells_sharing_peak)) %>%
  dplyr::select(-clust)
# Tab contenant les 200 peaks les plus partagés par les cellules du cluster1
clust1_top200 = head(tab_clust1, 200)
clust1_top200 = as.vector(clust1_top200$peak)

# Comparer les deux listes de peaks obtenues 
table(clust0_top200 == clust1_top200) # 4 peaks en commun et 196 peaks différents 

# Extraire les peaks qui ne sont présents que dans le clust0 ou que dans le clust1
clust0_top200_spe = clust0_top200[(clust0_top200 == clust1_top200) != TRUE]
clust1_top200_spe = clust1_top200[(clust0_top200 == clust1_top200) != TRUE]

# Utiliser closest feature sur tous ces peaks par cluster
gene_clust0 = ClosestFeature(seurat_obj, regions = clust0_top200_spe)
gene_clust1 = ClosestFeature(seurat_obj, regions = clust1_top200_spe)

# GO clust0
name_correspondance = bitr(gene_clust0$gene_id, fromType = "ENSEMBL", toType = "ENTREZID", OrgDb = "org.Hs.eg.db")
colnames(gene_clust0)[3] = "ENSEMBL"
gene_clust0 = inner_join(gene_clust0, name_correspondance, by = "ENSEMBL")
ego_clust0 <- enrichGO(gene = gene_clust0$ENTREZID,
       OrgDb         = org.Hs.eg.db,
       ont           = "ALL", # ont = ALL => cellular components, cellular pathway...
       pAdjustMethod = "BH",
       pvalueCutoff  = 0.05,
       qvalueCutoff  = 0.2,
       readable      = TRUE)
go_200peaks_clust0 = dotplot(ego_clust0, showCategory = 20)
go_200peaks_clust0

# GO clust1
name_correspondance = bitr(gene_clust1$gene_id, fromType = "ENSEMBL", toType = "ENTREZID", OrgDb = "org.Hs.eg.db")
colnames(gene_clust1)[3] = "ENSEMBL"
gene_clust1 = inner_join(gene_clust1, name_correspondance, by = "ENSEMBL")
ego_clust1 <- enrichGO(gene = gene_clust1$ENTREZID,
       OrgDb         = org.Hs.eg.db,
       ont           = "ALL", # ont = ALL => cellular components, cellular pathway...
       pAdjustMethod = "BH",
       pvalueCutoff  = 0.05,
       qvalueCutoff  = 0.2,
       readable      = TRUE)
go_200peaks_clust1 = dotplot(ego_clust1, showCategory = 20)
go_200peaks_clust1

# Save and clean working space 
ggsave(plot = go_200peaks_clust0, 
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_go_top200peaks_clust0.png"),
       width = 6, height = 6)
ggsave(plot = go_200peaks_clust1, 
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_", res, "_go_top200peaks_clust1.png"),
       width = 6, height = 6)
rm(clust0_top200, clust0_top200_spe, clust1_top200, clust1_top200_spe, tab_clust0, tab_clust1)
rm(ego_clust0, ego_clust1, gene_clust0, gene_clust1, name_correspondance, go_200peaks_clust0, go_200peaks_clust1)
```

A RETRAVAILLER / COMPLETER 


```{r, AddChromatinModule, results = 'hold', fig.width=20, fig.height=16}

# https://satijalab.org/signac/reference/addchromatinmodule
# https://github.com/timoast/signac/issues/185

loadRData<-function(fileName){
  #loads an RData file, and returns it
  load(fileName)
  get(ls()[ls()!="fileName"])
  
}

extract_peak_calista = function(dir_tab_calista, dir_prom_gene_fantom_gr, seurat_obj) {
  
  ###############################################################
  #### Pour chaque cluster de CALISTA, extraire la liste de gènes
  ###############################################################
  
  # Chargement des listes de gènes 
  calista_clust = read.table(dir_tab_calista, sep = "")
  # Renommer la colonne pour qu'elle corresponde à celle du tableau de la BDD prom_gene_fantom
  colnames(calista_clust) = "gene"
  
  #############################################################################
  #### Pour chaque liste de gène, associer la région correspondant au promoteur
  #############################################################################
  
  # Chargement du tableau faisant le lien entre les promoteurs FANTOM5 et les gènes associés 
  prom_gene_fantom_gr = loadRData(dir_prom_gene_fantom_gr)
  prom_gene_fantom_df = as.data.frame(prom_gene_fantom_gr) 
  
  # Attention, certaines façons de noter les gènes ne correspondent pas (- au lieu de .) : renommer les gènes calista
  calista_clust = calista_clust %>% dplyr::mutate(gene = str_replace_all(gene, "_", "."))

  ## Correspondance entre gènes de CALISTA et promoteurs 
  calista_clust_prom = left_join(calista_clust, prom_gene_fantom_df, by = "gene")

  # Certains gènes n'étaient pas dans la liste de la BDD prom_gene_fantom_df : on les enlève
  calista_clust_prom = na.omit(calista_clust_prom)

  # Transformer en Grange 
  calista_clust_gr = makeGRangesFromDataFrame(calista_clust_prom,
                                             seqnames.field="seqnames",
                                             start.field="start",
                                             end.field="end",
                                             strand.field="strand")

  #######################################################################################
  #### Trouver l'overlap entre les régions des promoteurs CALISTA et les peaks de scATAC
  #######################################################################################

  # on fait l'intersection/overlap de ces promoteurs avec nos peaks scATAC (tous les peaks)
  overlap = findOverlaps(query = calista_clust_gr, 
                         subject = seurat_obj@assays$peaks@ranges)

  # Récupérer les peaks de scATAC qui overlappent
  peaks =  seurat_obj@assays$peaks@ranges[subjectHits(overlap)]
  peaks_name_sc_calista = peaks$peaks_name
  return(peaks_name_sc_calista)

}

dir_prom_gene_fantom_gr = "/home/rparmentier/Documents/MARS-ATAC/data/MARS-ATAC_TF_prom_Expr_Ravi/data_fantom/prom_gene_fantom_gr.rdata"
  
list_features = list("calista1"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster1_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = seurat_obj),
                     "calista2"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster2_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = seurat_obj),
                     "calista3"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster3_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = seurat_obj),
                     "calista4"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster4_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = seurat_obj),
                     "calista5"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster5_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = seurat_obj))

###############################################################
#### Donner ces listes de peaks à la fonction AddChromatinModule
###############################################################
# Espèrer que le gros cluster corresponde au cluster 2 de Calista et que le petit au cluster 3/4/5
# Ou alors  espèrer que le gros cluster ait une signature plus "souche" que le cluster petit

seurat_obj = AddChromatinModule(object = seurat_obj,
                                features = list_features, 
                                genome = genome(seurat_obj),  # genome stocké à l'intérieur de l'objet seurat
                                verbose = TRUE)

plot_calista_umap = FeaturePlot(object = seurat_obj,
                                features = c("calista1", "calista2", "calista3", "calista4", "calista5"),
                                cols = c("blue", "green", "yellow", "orange", "red"),
                                keep.scale = "all")
plot_calista_umap


# Moyenne des scores du clust0 vs moyenne des scores du clust1
clust0 = readRDS("/home/rparmentier/Bureau/sc_ATAC_analysis/Git_sc_ATAC_analysis/exp/complete_Seurat_procedure/20220322/seurat_clust0_dim2-30_res.0.05.rds")
list_features_clust0 = list("calista1"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster1_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust0),
                     "calista2"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster2_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust0),
                     "calista3"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster3_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust0),
                     "calista4"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster4_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust0),
                     "calista5"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster5_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust0))
clust0 = AddChromatinModule(object = clust0,
                                features = list_features_clust0, 
                                genome = genome(clust0),  # genome stocké à l'intérieur de l'objet seurat
                                verbose = TRUE)

clust1 = readRDS("/home/rparmentier/Bureau/sc_ATAC_analysis/Git_sc_ATAC_analysis/exp/complete_Seurat_procedure/20220322/seurat_clust1_dim2-30_res.0.05.rds")
list_features_clust1 = list("calista1"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster1_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust1),
                     "calista2"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster2_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust1),
                     "calista3"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster3_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust1),
                     "calista4"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster4_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust1),
                     "calista5"= extract_peak_calista(
  dir_tab_calista = paste0(dir_git, "data/list_gene_cluster5_Pearson_cutoff_0.7_MinCell_5_donor1.csv"),
  dir_prom_gene_fantom_gr = dir_prom_gene_fantom_gr,seurat_obj = clust1))
clust1 = AddChromatinModule(object = clust1,
                                features = list_features_clust1, 
                                genome = genome(clust1),  # genome stocké à l'intérieur de l'objet seurat
                                verbose = TRUE)

tab_score = data.frame(cluster = c("clust0_mean_score", "clust1_mean_score", "clust0_median_score", "clust1_median_score"),
                       calista1 = c(mean(clust0$calista1), mean(clust1$calista1), median(clust0$calista1), median(clust1$calista1)),
                       calista2 = c(mean(clust0$calista2), mean(clust1$calista2), median(clust0$calista2), median(clust1$calista2)),
                       calista3 = c(mean(clust0$calista3), mean(clust1$calista3), median(clust0$calista3), median(clust1$calista3)),
                       calista4 = c(mean(clust0$calista4), mean(clust1$calista4), median(clust0$calista4), median(clust1$calista4)),
                       calista5 = c(mean(clust0$calista5), mean(clust1$calista5), median(clust0$calista5), median(clust1$calista5)))
tab_score

# Save object and clean working space
ggsave(plot = plot_calista_umap,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_umap_calista.png"),
       width = 12, height = 16)

ggsave(plot = plot_calista_umap,
       filename = paste0(dir_output, currentDate, "/plot_dim", dims_choice_char, "_umap_calista.pdf"),
       width = 16, height = 20)

rm(calista_clust1, calista_clust2, calista_clust3, calista_clust4, calista_clust5)
rm(gene_grange_prom, gene_grange_prom_list, list_peaks_prom)

```


Laisser tomber la differential analysis ?

```{r, TEST - Find Differential Accessibility}

# https://satijalab.org/seurat/reference/findmarkers

# Extract cells from clust0 and clust1
# clust0_cells = names(seurat_obj$peaks_snn_res.0.05[which(seurat_obj$peaks_snn_res.0.05 == 0)])
# nbcells_clust0 = length(clust0_cells)
# clust1_cells = names(seurat_obj$peaks_snn_res.0.05[which(seurat_obj$peaks_snn_res.0.05 == 1)])
# nbcells_clust1 = length(clust1_cells)


#######################################################################################################
# Test sur le logfc.threshold  => on s'intéresse aux pvalue adjust
#######################################################################################################

# Travail avec object downsamplé sinon c'est trop long ! 
# seurat_dwn = readRDS(file = paste0(dir_output, "20220302", "/seurat_obj_geneact_dim2-30.rds")) 
# 
# ###################
# # test 0.25
# ###################
# 
# # Compare clusters
# test_0.25 <- FindMarkers(
#   object = seurat_dwn,
#   ident.1 = 0, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   ident.2 = 1, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   min.pct = 0.05,  # au minimum le peak doit être partagé par 5% de la population pour être pris en compte
#   test.use = 'LR',
#   latent.vars = 'peak_region_fragments',
#   verbose = TRUE,
#   logfc.threshold = 0.25 # on sélectionne seulement les peaks pour lesquels log2FC > 0.25 ou < - 0.25 ?
# )

# On regarde les pvalues 
# pval_0.25 = test_0.25$p_val_adj
# min(pval_0.25) # 5.271362e-08
# max(pval_0.25) # 1
# 
# # Extract peaks with log2FC > 0.5 # attention, c'est possible que la pvalue soit pourrie ?
# gene_open_0.25 = rownames(test_0.25[test_0.25$avg_log2FC > 0.5, ])
# DA_openPeaks_0.25 <- test_0.25 %>% 
#   tibble::rownames_to_column(var = "peak") %>%
#   filter(peak %in% gene_open_0.25)
# # 13 peaks = 10 avec une pvalue adjust ok et 3 avec une pvalue pourrie
# 
# # Extract peaks with log2FC < - 0.5
# gene_close_0.25 = rownames(test_0.25[test_0.25$avg_log2FC < -0.5, ])
# DA_closePeaks_0.25 = test_0.25 %>% 
#   tibble::rownames_to_column(var = "peak") %>%
#   filter(peak %in% gene_close_0.25)
# # 28 peaks : 6 avec une pvalue pourrie 
# 
# plot_025 <- ggplot() +
#   geom_point(
#     data = test_0.25, 
#     aes(x = avg_log2FC, y = -1 * log10(p_val_adj)), 
#     size = 3, alpha = 0.5, shape = 21, stroke = 2) +
#   geom_hline(aes(yintercept = 2), colour = "red", linetype = "dashed") +
#   geom_text(label = "p-value = 0.01", colour = "red", aes(x = 0, y = 2.5)) +
#   ylim(NA, 20) +
#   labs(x = "log2(FoldChange)", y = "-log10(Pvalue_Adjust)") +
#   theme(axis.line.y = element_line(color = "black"),
#         axis.line.x = element_line(color = "black"),
#         legend.text = element_text(size = 10),
#         legend.title = element_text(size = 11),
#         axis.title = element_text(size = 10))
# plot_025
# 
# ###################
# # test 0.1
# ###################
# 
# test_0.1 <- FindMarkers(
#   object = seurat_dwn,
#   ident.1 = 0, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   ident.2 = 1, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   min.pct = 0.05,  # au minimum le peak doit être partagé par 5% de la population pour être pris en compte
#   test.use = 'LR',
#   latent.vars = 'peak_region_fragments',
#   verbose = TRUE,
#   logfc.threshold = 0.1
# )
# 
# pval_0.1 = test_0.1$p_val_adj
# min(pval_0.1) # 5.271362e-08
# max(pval_0.1) # 1
# 
# # Extract peaks with log2FC > 0.5 # attention, c'est possible que la pvalue soit pourrie ?
# gene_open_0.1 = rownames(test_0.1[test_0.1$avg_log2FC > 0.5, ])
# DA_openPeaks_0.1 <- test_0.1 %>% 
#   tibble::rownames_to_column(var = "peak") %>%
#   filter(peak %in% gene_open_0.1)
# # idem que pour 0.25
# 
# # Extract peaks with log2FC < - 0.5
# gene_close_0.1 = rownames(test_0.1[test_0.1$avg_log2FC < -0.5, ])
# DA_closePeaks_0.1 = test_0.1 %>% 
#   tibble::rownames_to_column(var = "peak") %>%
#   filter(peak %in% gene_close_0.1)
# # idem que pour 0.25
# 
# plot_01 <- ggplot() +
#   geom_point(
#     data = test_0.1, 
#     aes(x = avg_log2FC, y = -1 * log10(p_val_adj)), 
#     size = 3, alpha = 0.5, shape = 21, stroke = 2) +
#   geom_hline(aes(yintercept = 2), colour = "red", linetype = "dashed") +
#   geom_text(label = "p-value = 0.01", colour = "red", aes(x = 0, y = 2.5)) +
#   ylim(NA, 20) +
#   labs(x = "log2(FoldChange)", y = "-log10(Pvalue_Adjust)") +
#   theme(axis.line.y = element_line(color = "black"),
#         axis.line.x = element_line(color = "black"),
#         legend.text = element_text(size = 10),
#         legend.title = element_text(size = 11),
#         axis.title = element_text(size = 10))
# plot_01

###################
# test 0
###################

# test_0 <- FindMarkers(
#   object = seurat_dwn,
#   ident.1 = 0, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   ident.2 = 1, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   min.pct = 0.05,  # au minimum le peak doit être partagé par 5% de la population pour être pris en compte
#   test.use = 'LR',
#   latent.vars = 'peak_region_fragments',
#   verbose = TRUE,
#   logfc.threshold = 0
# )
# 
# pval_0 = test_0$p_val_adj
# min(pval_0) # 5.271362e-08
# max(pval_0)
# 
# # Extract peaks with log2FC > 0.5 # attention, c'est possible que la pvalue soit pourrie ?
# gene_open_0 = rownames(test_0[test_0$avg_log2FC > 0.5, ])
# DA_openPeaks_0 <- test_0 %>% 
#   tibble::rownames_to_column(var = "peak") %>%
#   filter(peak %in% gene_open_0)
# # idem que 0.25 et 0.1
# 
# # Extract peaks with log2FC < - 0.5
# gene_close_0 = rownames(test_0[test_0$avg_log2FC < -0.5, ])
# DA_closePeaks_0 = test_0 %>% 
#   tibble::rownames_to_column(var = "peak") %>%
#   filter(peak %in% gene_close_0)
# # idem que 0.25 et 0.1

# plot <- ggplot() +
#   geom_point(
#     data = test_0, 
#     aes(x = avg_log2FC, y = -1 * log10(p_val_adj)), 
#     size = 3, alpha = 0.5, shape = 21, stroke = 2) +
#   geom_hline(aes(yintercept = 2), colour = "red", linetype = "dashed") +
#   geom_text(label = "p-value = 0.01", colour = "red", aes(x = 0, y = 2.5)) +
#   ylim(NA, 20) +
#   labs(x = "log2(FoldChange)", y = "-log10(Pvalue_Adjust)") +
#   theme(axis.line.y = element_line(color = "black"),
#         axis.line.x = element_line(color = "black"),
#         legend.text = element_text(size = 10),
#         legend.title = element_text(size = 11),
#         axis.title = element_text(size = 10))
# plot

###################
# Pour résumer : quand on joue sur le paramètre logfc.threshold, on augmente le nombre de données qu'on récupère dans le tableau de sortie
# car il n'y a plus de filtre appliqué sur les résultats récupérés. Toutefois, on récupère toujours les mêmes peaks avec log2FC > 0.5 ou < 0.5 car cela ne change pas.
###################
  
##########################################################################################################################
# ident.1 : identity class to define markers for 
# ident.2 : a second identity class for comparison
# logfc.threshold : limit testing to genes which show, on average, at least X-fold difference (log-scale) between the two groups of cells. Default is 0.25 Increasing logfc.threshold speeds up the function, but can miss weaker signals.
###############################################################################################


```

```{r, Find Differential Accessibility}

# 1min de process
# da_peaks_0.25 <- FindMarkers(
#   object = seurat_obj,
#   ident.1 = 0, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   ident.2 = 1, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
#   min.pct = 0.05,  # au minimum le peak doit être partagé par 5% de la population pour être pris en compte
#   test.use = 'LR',
#   latent.vars = 'peak_region_fragments',
#   verbose = TRUE,
#   logfc.threshold = 0.25 # on sélectionne seulement les peaks pour lesquels log2FC > 0.25 ou < - 0.25
# )

DefaultAssay(seurat_obj) <- 'peaks'
# 2min15s de process => on commence à voir des FC positif mais ils étaient inférieurs à 0.25 c'est pour ça qu'on ne les voyait pas
test <- FindMarkers(
  object = seurat_obj,
  ident.1 = 0, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
  ident.2 = 1, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
  min.pct = 0.05,  # au minimum le peak doit être partagé par 5% de la population pour être pris en compte
  test.use = 'LR',
  latent.vars = 'peak_region_fragments',
  verbose = TRUE,
  logfc.threshold = 0.2 # on sélectionne seulement les peaks pour lesquels log2FC > 0.2 ou < - 0.2
)

# Extract peaks with log2FC > 0.5 # attention, c'est possible que la pvalue soit pourrie ?
gene_open_0.2 = rownames(da_peaks_0.2[da_peaks_0.2$avg_log2FC > 0.5, ])
DA_openPeaks_0.2 <- da_peaks_0.2 %>%
  tibble::rownames_to_column(var = "peak") %>%
  filter(peak %in% gene_open_0.2)
# vide 

# Extract peaks with log2FC < - 0.5
gene_close_0.2 = rownames(da_peaks_0.2[da_peaks_0.2$avg_log2FC < -0.5, ])
DA_closePeaks_0.2 = da_peaks_0.2 %>%
  tibble::rownames_to_column(var = "peak") %>%
  filter(peak %in% gene_close_0.2)
# 479

da_peaks_0.2_inverse <- FindMarkers(
  object = seurat_obj,
  ident.1 = 1, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
  ident.2 = 0, # possibilité de passer le numéro du cluster ou un vecteur avec le nom des cellules
  min.pct = 0.05,  # au minimum le peak doit être partagé par 5% de la population pour être pris en compte
  test.use = 'LR',
  latent.vars = 'peak_region_fragments',
  verbose = TRUE,
  logfc.threshold = 0.2 # on sélectionne seulement les peaks pour lesquels log2FC > 0.2 ou < - 0.2
)

# Extract peaks with log2FC > 0.5 # attention, c'est possible que la pvalue soit pourrie ?
gene_open_0.2_inverse = rownames(da_peaks_0.2_inverse[da_peaks_0.2_inverse$avg_log2FC > 0.5, ])
DA_openPeaks_0.2_invers <- da_peaks_0.2_inverse %>%
  tibble::rownames_to_column(var = "peak") %>%
  filter(peak %in% gene_open_0.2_inverse)
# 479 

# Extract peaks with log2FC < - 0.5
gene_close_0.2_inverse = rownames(da_peaks_0.2_inverse[da_peaks_0.2_inverse$avg_log2FC < -0.5, ])
DA_closePeaks_0.2_inverse = da_peaks_0.2_inverse %>%
  tibble::rownames_to_column(var = "peak") %>%
  filter(peak %in% gene_close_0.2_inverse)
# vide

table(gene_open_0.2_inverse == gene_close_0.2)


# quand on veut essayer logfc.threshold = 0 : 1h45m49s de process

plot <- ggplot() +
  geom_point(
    data = test_0, 
    aes(x = avg_log2FC, y = -1 * log10(p_val_adj)), 
    size = 3, alpha = 0.5, shape = 21, stroke = 2) +
  geom_hline(aes(yintercept = 2), colour = "red", linetype = "dashed") +
  geom_text(label = "p-value = 0.01", colour = "red", aes(x = 0, y = 2.5)) +
  ylim(NA, 20) +
  labs(x = "log2(FoldChange)", y = "-log10(Pvalue_Adjust)") +
  theme(axis.line.y = element_line(color = "black"),
        axis.line.x = element_line(color = "black"),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 11),
        axis.title = element_text(size = 10))
plot

# avg_logFC: Positive values indicate that the gene is more highly expressed in the first group
# pct.1: The percentage of cells where the gene is detected in the first group
# pct.2: The percentage of cells where the gene is detected in the second group
# si foldchange > 0.5, alors cells de ident1 plus accessibles que celles de ident2
# si foldchange < -0.5, alors cells de ident1 moins accessibles que celles de ident2


fc = FoldChange(object = seurat_obj,
                ident.1 = 0,
                ident.2 = 1)




# Autres résolutions => les clusters sont pas les mêmes, attention à ident1 et ident2

```

```{r Identifying peaks with high fold change}

# Place peaks on genome and determine the closest gene
# on obtient un tableau => vérifier si on a l'info de la fiabilité de l'attribution des gènes dans les peaks
DA_closePeaks_gene <- ClosestFeature(seurat_obj, regions = DA_closePeaks)
head(DA_closePeaks_gene)


```

```{r Gene Ontology}

# Sur les peaks qui sont plus fermés : 

# Code issu de l'analyse MARS ATAC = ne pas modifier
name_correspondace = bitr(DA_closePeaks_gene$gene_id, fromType = "ENSEMBL", toType = "ENTREZID", OrgDb = "org.Hs.eg.db")
colnames(DA_closePeaks_gene)[3] = "ENSEMBL"
# garder seulement les gènes dont on a trouvé la correspondance du nom dans la BDD
DA_closePeaks_gene = inner_join(DA_closePeaks_gene, name_correspondace, by = "ENSEMBL")

# ont = ALL => cellular components, cellular pathway...
ego <- enrichGO(gene = DA_closePeaks_gene$ENTREZID,
       OrgDb         = org.Hs.eg.db,
       ont           = "ALL",
       pAdjustMethod = "BH",
       pvalueCutoff  = 0.05,
       qvalueCutoff  = 0.2,
       readable      = TRUE)

dotplot(ego, showCategory = 20)


# refaire la même chose (ego) avec les foldchange positifs => pour avoir l'info de l'autre cluster
```





```{r}
sessionInfo()
```








